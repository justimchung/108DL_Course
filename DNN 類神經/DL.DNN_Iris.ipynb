{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHs1wDS61W9k"
   },
   "source": [
    "# Deep learning for Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2663,
     "status": "ok",
     "timestamp": 1584155548988,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "dX6IkRHmyxEQ",
    "outputId": "17f2d509-3852-40cf-84e7-215abf11aced"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "# 如果在 coLab 上執行這個程式碼，那要跑下一行，選擇 TensorFlow 2.x 版本\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9803,
     "status": "ok",
     "timestamp": 1584155556140,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "NayWhPA91Sje",
    "outputId": "38ec21ef-ebeb-4758-906c-92851cd4b871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow and check out the version\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbHw6iOP2Jrs"
   },
   "source": [
    "## Import Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11395,
     "status": "ok",
     "timestamp": 1584155557740,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "Ejx7Oy_02Op4",
    "outputId": "a033d3b6-e458-46c1-f8d8-67765cc64c52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'http://bit.ly/IEMIRIS'\n",
    "df = pd.read_csv(url)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11388,
     "status": "ok",
     "timestamp": 1584155557741,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "bB0adzta6TMR",
    "outputId": "80023500-004b-4ea9-e568-312dffb35029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2JCCU-5W8Dn"
   },
   "source": [
    "## Split the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11382,
     "status": "ok",
     "timestamp": 1584155557741,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "X03gUbC16ZxE",
    "outputId": "978dd194-e568-4731-fef4-8e21603a9041"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Species\n",
       "0  Iris-setosa\n",
       "1  Iris-setosa\n",
       "2  Iris-setosa\n",
       "3  Iris-setosa\n",
       "4  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.loc[:, ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y = df.loc[:, ['Species']]\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1584161276526,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "0qGdp4Ry6-DA",
    "outputId": "94168309-08ff-4fff-b287-2f904475e449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "0            5.1           3.5            1.4           0.2\n",
       "1            4.9           3.0            1.4           0.2\n",
       "2            4.7           3.2            1.3           0.2\n",
       "3            4.6           3.1            1.5           0.2\n",
       "4            5.0           3.6            1.4           0.2"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 另一種更簡潔的寫法 (another short-hand style)\n",
    "# 第一個 : 代表取所有的 row 的資料，之後的 0:4 代表取第 0 到第 3 個 columns (注意，不包含第 4 個 column)\n",
    "# The : means the retrival of all the rows. 0:4 means that we want to obtain the first (i.e., 0) to the third (i.e., 4-1 = 3) columns \n",
    "x = df.iloc[:, 0:4]\n",
    "x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTVu_pduCDvn"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqrEC5-WC0df"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LiyxR2e-7ZJq"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design the model\n",
    "\n",
    "The model is as following (see the following figure). \n",
    "\n",
    "The input layer contains 4 units.\n",
    "\n",
    "There are 8 neurals with the ``relu`` activation function in the hidden layer.\n",
    "\n",
    "The output layer contains 3 neurals.\n",
    "\n",
    "下圖展示了我們的模型。\n",
    "\n",
    "輸入層有 4 個元素。\n",
    "\n",
    "隱藏層有 8 個神經元。使用 relu 做為激活函數。\n",
    "\n",
    "最後輸出層有 3 個神經元，每一個神經元對應一種鳶尾花的類別。\n",
    "\n",
    "![](iris_dnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11366,
     "status": "ok",
     "timestamp": 1584155557745,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "R6tJuDsR210S",
    "outputId": "1483ee0e-2b8b-40c9-d0ed-9ac8fc4cd813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "#first input layer\n",
    "model.add(keras.layers.Dense(8, input_dim=4, activation='relu'))\n",
    "#output layer\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJovpelbkSWV"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruSDiJZbKBPh"
   },
   "source": [
    "## Train our model\n",
    "\n",
    "``Fit`` function trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "\n",
    "The document is [here](https://keras.io/models/model/).\n",
    "\n",
    "使用 ``fit`` 函式來訓練我們設計好的模型。\n",
    "\n",
    "相關說明請參考[這裏](https://keras.io/models/model/)。\n",
    "\n",
    "Important parameters (重要參數)：\n",
    "- **x**: Input data. 輸入的資料，即 x_train\n",
    "- **y**: Target data. 所要預測的對象，即 y_train\n",
    "- **epochs**: Number of epochs to train the model. 要訓練的回合數。回合數越高，可能有較高的 accuracy，但也可能造成 overfit。\n",
    "- **verbos**: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 訓練過程中，要秀出訓練中的訊息嗎？ 0 代表不秀出任何訊息。 1 為預設值，代表秀出 progress bar，2 代表每一 epoch 秀一行。\n",
    "- **batch_size**: Number of samples per gradient update. 做梯度更新時，一次要考量多少的資料量。預設值是 32。 \n",
    "\n",
    "Returns (回傳值)\n",
    "\n",
    "A History object. Its ``History.history`` attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
    "\n",
    "回傳一個名為 History 的物件，此物件中的 history (即 ``History.history``) 記錄著訓練過程中每一個 epoch 的 loss values 以及評量準則的值 (例如你的評量準則是 accuracy，那就會記錄 accuracy)。如果你有指定驗證集（validation set）的話，那也會順便回傳驗證集的 validation loss，以及驗證集的評量準則值. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19097,
     "status": "ok",
     "timestamp": 1584155565484,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "yhjXmNYKk_78",
    "outputId": "6717d6e0-ae4d-4265-e8f0-f021142e4ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Train on 105 samples\n",
      "Epoch 1/500\n",
      "105/105 [==============================] - 1s 5ms/sample - loss: 1.8552 - accuracy: 0.2000\n",
      "Epoch 2/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 1.8138 - accuracy: 0.2000\n",
      "Epoch 3/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 1.7743 - accuracy: 0.2095\n",
      "Epoch 4/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.7359 - accuracy: 0.2095\n",
      "Epoch 5/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 1.6989 - accuracy: 0.2190\n",
      "Epoch 6/500\n",
      "105/105 [==============================] - 0s 90us/sample - loss: 1.6622 - accuracy: 0.2190\n",
      "Epoch 7/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 1.6275 - accuracy: 0.2190\n",
      "Epoch 8/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 1.5889 - accuracy: 0.2190\n",
      "Epoch 9/500\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 1.5557 - accuracy: 0.2190\n",
      "Epoch 10/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.5196 - accuracy: 0.2190\n",
      "Epoch 11/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 1.4857 - accuracy: 0.2190\n",
      "Epoch 12/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 1.4526 - accuracy: 0.2095\n",
      "Epoch 13/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.4201 - accuracy: 0.2095\n",
      "Epoch 14/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 1.3896 - accuracy: 0.2095\n",
      "Epoch 15/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 1.3599 - accuracy: 0.2095\n",
      "Epoch 16/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 1.3294 - accuracy: 0.2095\n",
      "Epoch 17/500\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 1.3027 - accuracy: 0.2095\n",
      "Epoch 18/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 1.2740 - accuracy: 0.2095\n",
      "Epoch 19/500\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 1.2469 - accuracy: 0.2095\n",
      "Epoch 20/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 1.2213 - accuracy: 0.2286\n",
      "Epoch 21/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 1.1954 - accuracy: 0.2476\n",
      "Epoch 22/500\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.1711 - accuracy: 0.2952\n",
      "Epoch 23/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 1.1478 - accuracy: 0.3143\n",
      "Epoch 24/500\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 1.1234 - accuracy: 0.3524\n",
      "Epoch 25/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 1.1022 - accuracy: 0.4095\n",
      "Epoch 26/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 1.0813 - accuracy: 0.4286\n",
      "Epoch 27/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 1.0614 - accuracy: 0.4571\n",
      "Epoch 28/500\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 1.0410 - accuracy: 0.4571\n",
      "Epoch 29/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 1.0224 - accuracy: 0.4667\n",
      "Epoch 30/500\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 1.0038 - accuracy: 0.5143\n",
      "Epoch 31/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.9864 - accuracy: 0.5714\n",
      "Epoch 32/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.9686 - accuracy: 0.5810\n",
      "Epoch 33/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.9517 - accuracy: 0.6000\n",
      "Epoch 34/500\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.9355 - accuracy: 0.6190\n",
      "Epoch 35/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.9202 - accuracy: 0.6286\n",
      "Epoch 36/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.9045 - accuracy: 0.6381\n",
      "Epoch 37/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.8908 - accuracy: 0.6381\n",
      "Epoch 38/500\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.8768 - accuracy: 0.6476\n",
      "Epoch 39/500\n",
      "105/105 [==============================] - 0s 163us/sample - loss: 0.8632 - accuracy: 0.6476\n",
      "Epoch 40/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.8498 - accuracy: 0.6762\n",
      "Epoch 41/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.8365 - accuracy: 0.6762\n",
      "Epoch 42/500\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8236 - accuracy: 0.6762\n",
      "Epoch 43/500\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.8112 - accuracy: 0.6667\n",
      "Epoch 44/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.7990 - accuracy: 0.6762\n",
      "Epoch 45/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7873 - accuracy: 0.6857\n",
      "Epoch 46/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7764 - accuracy: 0.6857\n",
      "Epoch 47/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.7651 - accuracy: 0.6857\n",
      "Epoch 48/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.7545 - accuracy: 0.6952\n",
      "Epoch 49/500\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.7440 - accuracy: 0.7238\n",
      "Epoch 50/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7342 - accuracy: 0.7238\n",
      "Epoch 51/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7237 - accuracy: 0.7238\n",
      "Epoch 52/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.7138 - accuracy: 0.7238\n",
      "Epoch 53/500\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7047 - accuracy: 0.7143\n",
      "Epoch 54/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.6954 - accuracy: 0.7143\n",
      "Epoch 55/500\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.6862 - accuracy: 0.7143\n",
      "Epoch 56/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.6772 - accuracy: 0.7143\n",
      "Epoch 57/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.6688 - accuracy: 0.7143\n",
      "Epoch 58/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.6604 - accuracy: 0.7143\n",
      "Epoch 59/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.6524 - accuracy: 0.7143\n",
      "Epoch 60/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.6447 - accuracy: 0.7238\n",
      "Epoch 61/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.6373 - accuracy: 0.7238\n",
      "Epoch 62/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.6300 - accuracy: 0.7238\n",
      "Epoch 63/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.6229 - accuracy: 0.7238\n",
      "Epoch 64/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.6161 - accuracy: 0.7238\n",
      "Epoch 65/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.6097 - accuracy: 0.7333\n",
      "Epoch 66/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.6030 - accuracy: 0.7333\n",
      "Epoch 67/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.5968 - accuracy: 0.7333\n",
      "Epoch 68/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.5908 - accuracy: 0.7333\n",
      "Epoch 69/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.5848 - accuracy: 0.7333\n",
      "Epoch 70/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.5792 - accuracy: 0.7429\n",
      "Epoch 71/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.5737 - accuracy: 0.7429\n",
      "Epoch 72/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.5683 - accuracy: 0.7714\n",
      "Epoch 73/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.5629 - accuracy: 0.7714\n",
      "Epoch 74/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.5577 - accuracy: 0.7810\n",
      "Epoch 75/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.5525 - accuracy: 0.7810\n",
      "Epoch 76/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.5476 - accuracy: 0.7905\n",
      "Epoch 77/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.5425 - accuracy: 0.8095\n",
      "Epoch 78/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.5378 - accuracy: 0.8190\n",
      "Epoch 79/500\n",
      "105/105 [==============================] - 0s 219us/sample - loss: 0.5332 - accuracy: 0.8286\n",
      "Epoch 80/500\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.5287 - accuracy: 0.8190\n",
      "Epoch 81/500\n",
      "105/105 [==============================] - 0s 227us/sample - loss: 0.5241 - accuracy: 0.8190\n",
      "Epoch 82/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.5199 - accuracy: 0.8190\n",
      "Epoch 83/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.5158 - accuracy: 0.8190\n",
      "Epoch 84/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.5116 - accuracy: 0.8190\n",
      "Epoch 85/500\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.5075 - accuracy: 0.8190\n",
      "Epoch 86/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.5037 - accuracy: 0.8190\n",
      "Epoch 87/500\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.4998 - accuracy: 0.8381\n",
      "Epoch 88/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.4961 - accuracy: 0.8381\n",
      "Epoch 89/500\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.4923 - accuracy: 0.8381\n",
      "Epoch 90/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.4888 - accuracy: 0.8381\n",
      "Epoch 91/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.4852 - accuracy: 0.8381\n",
      "Epoch 92/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.4817 - accuracy: 0.8381\n",
      "Epoch 93/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.4784 - accuracy: 0.8381\n",
      "Epoch 94/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.4750 - accuracy: 0.8476\n",
      "Epoch 95/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.4718 - accuracy: 0.8476\n",
      "Epoch 96/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.4686 - accuracy: 0.8476\n",
      "Epoch 97/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.4654 - accuracy: 0.8476\n",
      "Epoch 98/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.4624 - accuracy: 0.8571\n",
      "Epoch 99/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.4593 - accuracy: 0.8571\n",
      "Epoch 100/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.4565 - accuracy: 0.8571\n",
      "Epoch 101/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.4535 - accuracy: 0.8667\n",
      "Epoch 102/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.4507 - accuracy: 0.8667\n",
      "Epoch 103/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.4480 - accuracy: 0.8667\n",
      "Epoch 104/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.4452 - accuracy: 0.8667\n",
      "Epoch 105/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.4426 - accuracy: 0.8667\n",
      "Epoch 106/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.4399 - accuracy: 0.8667\n",
      "Epoch 107/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.4373 - accuracy: 0.8667\n",
      "Epoch 108/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.4348 - accuracy: 0.8667\n",
      "Epoch 109/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.4323 - accuracy: 0.8667\n",
      "Epoch 110/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.4298 - accuracy: 0.8667\n",
      "Epoch 111/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.4274 - accuracy: 0.8667\n",
      "Epoch 112/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.4250 - accuracy: 0.8667\n",
      "Epoch 113/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.4226 - accuracy: 0.8667\n",
      "Epoch 114/500\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.4203 - accuracy: 0.8667\n",
      "Epoch 115/500\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.4180 - accuracy: 0.8667\n",
      "Epoch 116/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.4157 - accuracy: 0.8667\n",
      "Epoch 117/500\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.4134 - accuracy: 0.8667\n",
      "Epoch 118/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.4112 - accuracy: 0.8667\n",
      "Epoch 119/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.4088 - accuracy: 0.8667\n",
      "Epoch 120/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.4066 - accuracy: 0.8667\n",
      "Epoch 121/500\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.4045 - accuracy: 0.8667\n",
      "Epoch 122/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.4023 - accuracy: 0.8667\n",
      "Epoch 123/500\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.4002 - accuracy: 0.8667\n",
      "Epoch 124/500\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.3981 - accuracy: 0.8762\n",
      "Epoch 125/500\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.3961 - accuracy: 0.8762\n",
      "Epoch 126/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.3941 - accuracy: 0.8762\n",
      "Epoch 127/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.3921 - accuracy: 0.8762\n",
      "Epoch 128/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.3901 - accuracy: 0.8762\n",
      "Epoch 129/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.3882 - accuracy: 0.8857\n",
      "Epoch 130/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.3863 - accuracy: 0.8857\n",
      "Epoch 131/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3843 - accuracy: 0.8857\n",
      "Epoch 132/500\n",
      "105/105 [==============================] - 0s 156us/sample - loss: 0.3824 - accuracy: 0.8857\n",
      "Epoch 133/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.3805 - accuracy: 0.8857\n",
      "Epoch 134/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.3787 - accuracy: 0.8857\n",
      "Epoch 135/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.3768 - accuracy: 0.8857\n",
      "Epoch 136/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.3750 - accuracy: 0.8857\n",
      "Epoch 137/500\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.3733 - accuracy: 0.8857\n",
      "Epoch 138/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.3716 - accuracy: 0.8857\n",
      "Epoch 139/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.3698 - accuracy: 0.8857\n",
      "Epoch 140/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.3681 - accuracy: 0.8857\n",
      "Epoch 141/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.3664 - accuracy: 0.8857\n",
      "Epoch 142/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.3647 - accuracy: 0.8857\n",
      "Epoch 143/500\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.3630 - accuracy: 0.8857\n",
      "Epoch 144/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.3613 - accuracy: 0.8857\n",
      "Epoch 145/500\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.3595 - accuracy: 0.8857\n",
      "Epoch 146/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.3577 - accuracy: 0.8952\n",
      "Epoch 147/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.3560 - accuracy: 0.8952\n",
      "Epoch 148/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.3542 - accuracy: 0.9048\n",
      "Epoch 149/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.3526 - accuracy: 0.9048\n",
      "Epoch 150/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.3509 - accuracy: 0.9143\n",
      "Epoch 151/500\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.3492 - accuracy: 0.9143\n",
      "Epoch 152/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.3475 - accuracy: 0.9143\n",
      "Epoch 153/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.3459 - accuracy: 0.9143\n",
      "Epoch 154/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.3442 - accuracy: 0.9143\n",
      "Epoch 155/500\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.3425 - accuracy: 0.9238\n",
      "Epoch 156/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.3409 - accuracy: 0.9238\n",
      "Epoch 157/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.3392 - accuracy: 0.9333\n",
      "Epoch 158/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.3378 - accuracy: 0.9333\n",
      "Epoch 159/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.3360 - accuracy: 0.9333\n",
      "Epoch 160/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.3345 - accuracy: 0.9333\n",
      "Epoch 161/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.3329 - accuracy: 0.9429\n",
      "Epoch 162/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.3314 - accuracy: 0.9429\n",
      "Epoch 163/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.3299 - accuracy: 0.9429\n",
      "Epoch 164/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 0.3284 - accuracy: 0.9429\n",
      "Epoch 165/500\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.3269 - accuracy: 0.9429\n",
      "Epoch 166/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.3255 - accuracy: 0.9429\n",
      "Epoch 167/500\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.3240 - accuracy: 0.9429\n",
      "Epoch 168/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.3226 - accuracy: 0.9429\n",
      "Epoch 169/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.3211 - accuracy: 0.9429\n",
      "Epoch 170/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.3196 - accuracy: 0.9429\n",
      "Epoch 171/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.3183 - accuracy: 0.9429\n",
      "Epoch 172/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.3169 - accuracy: 0.9429\n",
      "Epoch 173/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.3155 - accuracy: 0.9429\n",
      "Epoch 174/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.3141 - accuracy: 0.9429\n",
      "Epoch 175/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.3127 - accuracy: 0.9429\n",
      "Epoch 176/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3113 - accuracy: 0.9429\n",
      "Epoch 177/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.3099 - accuracy: 0.9429\n",
      "Epoch 178/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.3086 - accuracy: 0.9429\n",
      "Epoch 179/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.3072 - accuracy: 0.9429\n",
      "Epoch 180/500\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.3061 - accuracy: 0.9429\n",
      "Epoch 181/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.3044 - accuracy: 0.9429\n",
      "Epoch 182/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.3031 - accuracy: 0.9429\n",
      "Epoch 183/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.3017 - accuracy: 0.9429\n",
      "Epoch 184/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.3006 - accuracy: 0.9429\n",
      "Epoch 185/500\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.2990 - accuracy: 0.9429\n",
      "Epoch 186/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2976 - accuracy: 0.9429\n",
      "Epoch 187/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.2964 - accuracy: 0.9429\n",
      "Epoch 188/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.2950 - accuracy: 0.9524\n",
      "Epoch 189/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.2937 - accuracy: 0.9524\n",
      "Epoch 190/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.2925 - accuracy: 0.9524\n",
      "Epoch 191/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.2911 - accuracy: 0.9524\n",
      "Epoch 192/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.2898 - accuracy: 0.9524\n",
      "Epoch 193/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.2886 - accuracy: 0.9524\n",
      "Epoch 194/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.2873 - accuracy: 0.9524\n",
      "Epoch 195/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.2861 - accuracy: 0.9524\n",
      "Epoch 196/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.2849 - accuracy: 0.9524\n",
      "Epoch 197/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.2837 - accuracy: 0.9524\n",
      "Epoch 198/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.2824 - accuracy: 0.9524\n",
      "Epoch 199/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.2813 - accuracy: 0.9524\n",
      "Epoch 200/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2801 - accuracy: 0.9524\n",
      "Epoch 201/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.2789 - accuracy: 0.9524\n",
      "Epoch 202/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.2777 - accuracy: 0.9524\n",
      "Epoch 203/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.2765 - accuracy: 0.9524\n",
      "Epoch 204/500\n",
      "105/105 [==============================] - 0s 90us/sample - loss: 0.2753 - accuracy: 0.9524\n",
      "Epoch 205/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.2742 - accuracy: 0.9524\n",
      "Epoch 206/500\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.2730 - accuracy: 0.9524\n",
      "Epoch 207/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.2718 - accuracy: 0.9524\n",
      "Epoch 208/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.2707 - accuracy: 0.9524\n",
      "Epoch 209/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.2696 - accuracy: 0.9524\n",
      "Epoch 210/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.2685 - accuracy: 0.9524\n",
      "Epoch 211/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.2673 - accuracy: 0.9524\n",
      "Epoch 212/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.2662 - accuracy: 0.9524\n",
      "Epoch 213/500\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.2651 - accuracy: 0.9524\n",
      "Epoch 214/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.2640 - accuracy: 0.9524\n",
      "Epoch 215/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.2629 - accuracy: 0.9524\n",
      "Epoch 216/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.2618 - accuracy: 0.9524\n",
      "Epoch 217/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.2606 - accuracy: 0.9524\n",
      "Epoch 218/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.2595 - accuracy: 0.9524\n",
      "Epoch 219/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.2584 - accuracy: 0.9524\n",
      "Epoch 220/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2573 - accuracy: 0.9524\n",
      "Epoch 221/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.2562 - accuracy: 0.9524\n",
      "Epoch 222/500\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.2550 - accuracy: 0.9524\n",
      "Epoch 223/500\n",
      "105/105 [==============================] - 0s 160us/sample - loss: 0.2539 - accuracy: 0.9524\n",
      "Epoch 224/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.2528 - accuracy: 0.9524\n",
      "Epoch 225/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.2517 - accuracy: 0.9524\n",
      "Epoch 226/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2506 - accuracy: 0.9524\n",
      "Epoch 227/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.2495 - accuracy: 0.9524\n",
      "Epoch 228/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.2484 - accuracy: 0.9619\n",
      "Epoch 229/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.2475 - accuracy: 0.9619\n",
      "Epoch 230/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.2465 - accuracy: 0.9619\n",
      "Epoch 231/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2454 - accuracy: 0.9619\n",
      "Epoch 232/500\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.2443 - accuracy: 0.9619\n",
      "Epoch 233/500\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.2433 - accuracy: 0.9619\n",
      "Epoch 234/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2423 - accuracy: 0.9619\n",
      "Epoch 235/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.2413 - accuracy: 0.9619\n",
      "Epoch 236/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.2402 - accuracy: 0.9619\n",
      "Epoch 237/500\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.2392 - accuracy: 0.9619\n",
      "Epoch 238/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2382 - accuracy: 0.9619\n",
      "Epoch 239/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.2372 - accuracy: 0.9619\n",
      "Epoch 240/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.2362 - accuracy: 0.9619\n",
      "Epoch 241/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.2352 - accuracy: 0.9619\n",
      "Epoch 242/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.2342 - accuracy: 0.9619\n",
      "Epoch 243/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.2332 - accuracy: 0.9619\n",
      "Epoch 244/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.2322 - accuracy: 0.9619\n",
      "Epoch 245/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2312 - accuracy: 0.9619\n",
      "Epoch 246/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.2302 - accuracy: 0.9619\n",
      "Epoch 247/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.2293 - accuracy: 0.9619\n",
      "Epoch 248/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.2283 - accuracy: 0.9619\n",
      "Epoch 249/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.2273 - accuracy: 0.9619\n",
      "Epoch 250/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.2264 - accuracy: 0.9619\n",
      "Epoch 251/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.2255 - accuracy: 0.9619\n",
      "Epoch 252/500\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.2245 - accuracy: 0.9619\n",
      "Epoch 253/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.2236 - accuracy: 0.9619\n",
      "Epoch 254/500\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.2226 - accuracy: 0.9619\n",
      "Epoch 255/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.2217 - accuracy: 0.9619\n",
      "Epoch 256/500\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.2208 - accuracy: 0.9619\n",
      "Epoch 257/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.2199 - accuracy: 0.9619\n",
      "Epoch 258/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.2190 - accuracy: 0.9619\n",
      "Epoch 259/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.2181 - accuracy: 0.9619\n",
      "Epoch 260/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.2172 - accuracy: 0.9619\n",
      "Epoch 261/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.2163 - accuracy: 0.9619\n",
      "Epoch 262/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.2153 - accuracy: 0.9619\n",
      "Epoch 263/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.2144 - accuracy: 0.9619\n",
      "Epoch 264/500\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.2134 - accuracy: 0.9619\n",
      "Epoch 265/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.2125 - accuracy: 0.9619\n",
      "Epoch 266/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.2117 - accuracy: 0.9619\n",
      "Epoch 267/500\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.2109 - accuracy: 0.9619\n",
      "Epoch 268/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.2100 - accuracy: 0.9619\n",
      "Epoch 269/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.2092 - accuracy: 0.9619\n",
      "Epoch 270/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.2083 - accuracy: 0.9619\n",
      "Epoch 271/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2074 - accuracy: 0.9619\n",
      "Epoch 272/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.2065 - accuracy: 0.9619\n",
      "Epoch 273/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.2057 - accuracy: 0.9619\n",
      "Epoch 274/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.2048 - accuracy: 0.9619\n",
      "Epoch 275/500\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.2039 - accuracy: 0.9619\n",
      "Epoch 276/500\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.2030 - accuracy: 0.9619\n",
      "Epoch 277/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 0.2022 - accuracy: 0.9619\n",
      "Epoch 278/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.2013 - accuracy: 0.9619\n",
      "Epoch 279/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 0.2004 - accuracy: 0.9619\n",
      "Epoch 280/500\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.1996 - accuracy: 0.9619\n",
      "Epoch 281/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.1987 - accuracy: 0.9619\n",
      "Epoch 282/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.1979 - accuracy: 0.9619\n",
      "Epoch 283/500\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.1971 - accuracy: 0.9619\n",
      "Epoch 284/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.1962 - accuracy: 0.9619\n",
      "Epoch 285/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1953 - accuracy: 0.9619\n",
      "Epoch 286/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.1944 - accuracy: 0.9619\n",
      "Epoch 287/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.1936 - accuracy: 0.9619\n",
      "Epoch 288/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.1927 - accuracy: 0.9619\n",
      "Epoch 289/500\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.1918 - accuracy: 0.9619\n",
      "Epoch 290/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.1910 - accuracy: 0.9619\n",
      "Epoch 291/500\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.1901 - accuracy: 0.9619\n",
      "Epoch 292/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.1893 - accuracy: 0.9619\n",
      "Epoch 293/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.1884 - accuracy: 0.9619\n",
      "Epoch 294/500\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.1875 - accuracy: 0.9619\n",
      "Epoch 295/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.1867 - accuracy: 0.9619\n",
      "Epoch 296/500\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.1859 - accuracy: 0.9619\n",
      "Epoch 297/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.1851 - accuracy: 0.9619\n",
      "Epoch 298/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.1843 - accuracy: 0.9619\n",
      "Epoch 299/500\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.1836 - accuracy: 0.9619\n",
      "Epoch 300/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.1826 - accuracy: 0.9619\n",
      "Epoch 301/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.1819 - accuracy: 0.9619\n",
      "Epoch 302/500\n",
      "105/105 [==============================] - 0s 90us/sample - loss: 0.1810 - accuracy: 0.9619\n",
      "Epoch 303/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.1802 - accuracy: 0.9619\n",
      "Epoch 304/500\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.1794 - accuracy: 0.9619\n",
      "Epoch 305/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.1785 - accuracy: 0.9619\n",
      "Epoch 306/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.1776 - accuracy: 0.9619\n",
      "Epoch 307/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.1767 - accuracy: 0.9619\n",
      "Epoch 308/500\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.1759 - accuracy: 0.9619\n",
      "Epoch 309/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.1749 - accuracy: 0.9619\n",
      "Epoch 310/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.1741 - accuracy: 0.9619\n",
      "Epoch 311/500\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.1732 - accuracy: 0.9619\n",
      "Epoch 312/500\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.1724 - accuracy: 0.9619\n",
      "Epoch 313/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.1716 - accuracy: 0.9619\n",
      "Epoch 314/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.1707 - accuracy: 0.9619\n",
      "Epoch 315/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.1699 - accuracy: 0.9619\n",
      "Epoch 316/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.1689 - accuracy: 0.9619\n",
      "Epoch 317/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.1680 - accuracy: 0.9619\n",
      "Epoch 318/500\n",
      "105/105 [==============================] - 0s 90us/sample - loss: 0.1671 - accuracy: 0.9619\n",
      "Epoch 319/500\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.1662 - accuracy: 0.9619\n",
      "Epoch 320/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1653 - accuracy: 0.9714\n",
      "Epoch 321/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.1643 - accuracy: 0.9714\n",
      "Epoch 322/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.1633 - accuracy: 0.9714\n",
      "Epoch 323/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.1624 - accuracy: 0.9714\n",
      "Epoch 324/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.1614 - accuracy: 0.9714\n",
      "Epoch 325/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.1606 - accuracy: 0.9714\n",
      "Epoch 326/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.1597 - accuracy: 0.9714\n",
      "Epoch 327/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.1587 - accuracy: 0.9714\n",
      "Epoch 328/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.1578 - accuracy: 0.9714\n",
      "Epoch 329/500\n",
      "105/105 [==============================] - 0s 163us/sample - loss: 0.1569 - accuracy: 0.9714\n",
      "Epoch 330/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.1560 - accuracy: 0.9714\n",
      "Epoch 331/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.1550 - accuracy: 0.9714\n",
      "Epoch 332/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.1543 - accuracy: 0.9714\n",
      "Epoch 333/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.1535 - accuracy: 0.9714\n",
      "Epoch 334/500\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.1525 - accuracy: 0.9714\n",
      "Epoch 335/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.1517 - accuracy: 0.9714\n",
      "Epoch 336/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.1508 - accuracy: 0.9714\n",
      "Epoch 337/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.1499 - accuracy: 0.9714\n",
      "Epoch 338/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.1490 - accuracy: 0.9714\n",
      "Epoch 339/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.1481 - accuracy: 0.9714\n",
      "Epoch 340/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.1474 - accuracy: 0.9714\n",
      "Epoch 341/500\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.1466 - accuracy: 0.9714\n",
      "Epoch 342/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.1458 - accuracy: 0.9714\n",
      "Epoch 343/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.1450 - accuracy: 0.9714\n",
      "Epoch 344/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.1442 - accuracy: 0.9714\n",
      "Epoch 345/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.1433 - accuracy: 0.9714\n",
      "Epoch 346/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.1424 - accuracy: 0.9714\n",
      "Epoch 347/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.1416 - accuracy: 0.9714\n",
      "Epoch 348/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.1409 - accuracy: 0.9714\n",
      "Epoch 349/500\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.1399 - accuracy: 0.9714\n",
      "Epoch 350/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.1391 - accuracy: 0.9714\n",
      "Epoch 351/500\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.1386 - accuracy: 0.9619\n",
      "Epoch 352/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.1376 - accuracy: 0.9714\n",
      "Epoch 353/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.1369 - accuracy: 0.9714\n",
      "Epoch 354/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.1362 - accuracy: 0.9714\n",
      "Epoch 355/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.1353 - accuracy: 0.9714\n",
      "Epoch 356/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.1346 - accuracy: 0.9714\n",
      "Epoch 357/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.1339 - accuracy: 0.9714\n",
      "Epoch 358/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.1331 - accuracy: 0.9714\n",
      "Epoch 359/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.1324 - accuracy: 0.9714\n",
      "Epoch 360/500\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.1317 - accuracy: 0.9714\n",
      "Epoch 361/500\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.1311 - accuracy: 0.9714\n",
      "Epoch 362/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.1305 - accuracy: 0.9714\n",
      "Epoch 363/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.1297 - accuracy: 0.9714\n",
      "Epoch 364/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1290 - accuracy: 0.9714\n",
      "Epoch 365/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.1284 - accuracy: 0.9714\n",
      "Epoch 366/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.1277 - accuracy: 0.9714\n",
      "Epoch 367/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.1270 - accuracy: 0.9714\n",
      "Epoch 368/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.1264 - accuracy: 0.9714\n",
      "Epoch 369/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.1257 - accuracy: 0.9714\n",
      "Epoch 370/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.1253 - accuracy: 0.9714\n",
      "Epoch 371/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.1246 - accuracy: 0.9714\n",
      "Epoch 372/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.1239 - accuracy: 0.9714\n",
      "Epoch 373/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.1234 - accuracy: 0.9714\n",
      "Epoch 374/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 0.1228 - accuracy: 0.9714\n",
      "Epoch 375/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.1223 - accuracy: 0.9714\n",
      "Epoch 376/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.1218 - accuracy: 0.9714\n",
      "Epoch 377/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.1212 - accuracy: 0.9714\n",
      "Epoch 378/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.1207 - accuracy: 0.9714\n",
      "Epoch 379/500\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.1201 - accuracy: 0.9714\n",
      "Epoch 380/500\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 0.1196 - accuracy: 0.9714\n",
      "Epoch 381/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.1191 - accuracy: 0.9714\n",
      "Epoch 382/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.1185 - accuracy: 0.9714\n",
      "Epoch 383/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.1181 - accuracy: 0.9714\n",
      "Epoch 384/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.1175 - accuracy: 0.9714\n",
      "Epoch 385/500\n",
      "105/105 [==============================] - 0s 90us/sample - loss: 0.1169 - accuracy: 0.9714\n",
      "Epoch 386/500\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.1164 - accuracy: 0.9714\n",
      "Epoch 387/500\n",
      "105/105 [==============================] - 0s 161us/sample - loss: 0.1160 - accuracy: 0.9714\n",
      "Epoch 388/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.1155 - accuracy: 0.9714\n",
      "Epoch 389/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.1151 - accuracy: 0.9714\n",
      "Epoch 390/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.1146 - accuracy: 0.9714\n",
      "Epoch 391/500\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.1141 - accuracy: 0.9714\n",
      "Epoch 392/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.1137 - accuracy: 0.9714\n",
      "Epoch 393/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.1133 - accuracy: 0.9714\n",
      "Epoch 394/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.1129 - accuracy: 0.9714\n",
      "Epoch 395/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.1124 - accuracy: 0.9714\n",
      "Epoch 396/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.1120 - accuracy: 0.9714\n",
      "Epoch 397/500\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.1116 - accuracy: 0.9714\n",
      "Epoch 398/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.1112 - accuracy: 0.9714\n",
      "Epoch 399/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.1108 - accuracy: 0.9714\n",
      "Epoch 400/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.1104 - accuracy: 0.9714\n",
      "Epoch 401/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.1101 - accuracy: 0.9714\n",
      "Epoch 402/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.1096 - accuracy: 0.9714\n",
      "Epoch 403/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.1093 - accuracy: 0.9714\n",
      "Epoch 404/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.1089 - accuracy: 0.9714\n",
      "Epoch 405/500\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1085 - accuracy: 0.9714\n",
      "Epoch 406/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.1081 - accuracy: 0.9714\n",
      "Epoch 407/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.1077 - accuracy: 0.9714\n",
      "Epoch 408/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.1073 - accuracy: 0.9714\n",
      "Epoch 409/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.1070 - accuracy: 0.9714\n",
      "Epoch 410/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.1066 - accuracy: 0.9714\n",
      "Epoch 411/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.1063 - accuracy: 0.9714\n",
      "Epoch 412/500\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.1059 - accuracy: 0.9714\n",
      "Epoch 413/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.1056 - accuracy: 0.9714\n",
      "Epoch 414/500\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.1052 - accuracy: 0.9714\n",
      "Epoch 415/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.1049 - accuracy: 0.9714\n",
      "Epoch 416/500\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.1045 - accuracy: 0.9714\n",
      "Epoch 417/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.1042 - accuracy: 0.9714\n",
      "Epoch 418/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.1039 - accuracy: 0.9714\n",
      "Epoch 419/500\n",
      "105/105 [==============================] - 0s 90us/sample - loss: 0.1036 - accuracy: 0.9714\n",
      "Epoch 420/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.1033 - accuracy: 0.9714\n",
      "Epoch 421/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.1030 - accuracy: 0.9714\n",
      "Epoch 422/500\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.1027 - accuracy: 0.9714\n",
      "Epoch 423/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.1024 - accuracy: 0.9714\n",
      "Epoch 424/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.1022 - accuracy: 0.9714\n",
      "Epoch 425/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.1018 - accuracy: 0.9714\n",
      "Epoch 426/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.1015 - accuracy: 0.9714\n",
      "Epoch 427/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.1012 - accuracy: 0.9714\n",
      "Epoch 428/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.1009 - accuracy: 0.9714\n",
      "Epoch 429/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.1005 - accuracy: 0.9714\n",
      "Epoch 430/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.1002 - accuracy: 0.9714\n",
      "Epoch 431/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.0999 - accuracy: 0.9714\n",
      "Epoch 432/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.0996 - accuracy: 0.9714\n",
      "Epoch 433/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.0993 - accuracy: 0.9714\n",
      "Epoch 434/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.0989 - accuracy: 0.9714\n",
      "Epoch 435/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.0986 - accuracy: 0.9714\n",
      "Epoch 436/500\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.0983 - accuracy: 0.9714\n",
      "Epoch 437/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.0980 - accuracy: 0.9714\n",
      "Epoch 438/500\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.0978 - accuracy: 0.9714\n",
      "Epoch 439/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.0974 - accuracy: 0.9714\n",
      "Epoch 440/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.0972 - accuracy: 0.9714\n",
      "Epoch 441/500\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.0970 - accuracy: 0.9714\n",
      "Epoch 442/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.0967 - accuracy: 0.9714\n",
      "Epoch 443/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.0964 - accuracy: 0.9714\n",
      "Epoch 444/500\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.0962 - accuracy: 0.9714\n",
      "Epoch 445/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.0958 - accuracy: 0.9714\n",
      "Epoch 446/500\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.0955 - accuracy: 0.9714\n",
      "Epoch 447/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.0953 - accuracy: 0.9714\n",
      "Epoch 448/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.0950 - accuracy: 0.9714\n",
      "Epoch 449/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.0947 - accuracy: 0.9714\n",
      "Epoch 450/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.0944 - accuracy: 0.9714\n",
      "Epoch 451/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.0942 - accuracy: 0.9714\n",
      "Epoch 452/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.0940 - accuracy: 0.9714\n",
      "Epoch 453/500\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.0937 - accuracy: 0.9714\n",
      "Epoch 454/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.0934 - accuracy: 0.9714\n",
      "Epoch 455/500\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.0932 - accuracy: 0.9714\n",
      "Epoch 456/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.0930 - accuracy: 0.9714\n",
      "Epoch 457/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.0929 - accuracy: 0.9714\n",
      "Epoch 458/500\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.0926 - accuracy: 0.9714\n",
      "Epoch 459/500\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.0923 - accuracy: 0.9714\n",
      "Epoch 460/500\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.0921 - accuracy: 0.9714\n",
      "Epoch 461/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.0918 - accuracy: 0.9714\n",
      "Epoch 462/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.0915 - accuracy: 0.9714\n",
      "Epoch 463/500\n",
      "105/105 [==============================] - 0s 90us/sample - loss: 0.0913 - accuracy: 0.9714\n",
      "Epoch 464/500\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.0911 - accuracy: 0.9714\n",
      "Epoch 465/500\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.0908 - accuracy: 0.9714\n",
      "Epoch 466/500\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.0905 - accuracy: 0.9714\n",
      "Epoch 467/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.0903 - accuracy: 0.9714\n",
      "Epoch 468/500\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.0900 - accuracy: 0.9714\n",
      "Epoch 469/500\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.0898 - accuracy: 0.9714\n",
      "Epoch 470/500\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.0895 - accuracy: 0.9714\n",
      "Epoch 471/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.0893 - accuracy: 0.9714\n",
      "Epoch 472/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.0891 - accuracy: 0.9714\n",
      "Epoch 473/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.0889 - accuracy: 0.9714\n",
      "Epoch 474/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.0886 - accuracy: 0.9714\n",
      "Epoch 475/500\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.0885 - accuracy: 0.9714\n",
      "Epoch 476/500\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.0882 - accuracy: 0.9714\n",
      "Epoch 477/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.0879 - accuracy: 0.9714\n",
      "Epoch 478/500\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.0877 - accuracy: 0.9714\n",
      "Epoch 479/500\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.0875 - accuracy: 0.9714\n",
      "Epoch 480/500\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.0873 - accuracy: 0.9714\n",
      "Epoch 481/500\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.0872 - accuracy: 0.9714\n",
      "Epoch 482/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.0871 - accuracy: 0.9714\n",
      "Epoch 483/500\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.0869 - accuracy: 0.9714\n",
      "Epoch 484/500\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.0866 - accuracy: 0.9714\n",
      "Epoch 485/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.0864 - accuracy: 0.9714\n",
      "Epoch 486/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.0862 - accuracy: 0.9714\n",
      "Epoch 487/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.0860 - accuracy: 0.9714\n",
      "Epoch 488/500\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.0858 - accuracy: 0.9714\n",
      "Epoch 489/500\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.0856 - accuracy: 0.9714\n",
      "Epoch 490/500\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.0854 - accuracy: 0.9714\n",
      "Epoch 491/500\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.0852 - accuracy: 0.9714\n",
      "Epoch 492/500\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.0850 - accuracy: 0.9714\n",
      "Epoch 493/500\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.0848 - accuracy: 0.9714\n",
      "Epoch 494/500\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.0845 - accuracy: 0.9714\n",
      "Epoch 495/500\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.0843 - accuracy: 0.9714\n",
      "Epoch 496/500\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.0841 - accuracy: 0.9714\n",
      "Epoch 497/500\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.0839 - accuracy: 0.9714\n",
      "Epoch 498/500\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.0838 - accuracy: 0.9714\n",
      "Epoch 499/500\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.0836 - accuracy: 0.9714\n",
      "Epoch 500/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.0834 - accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "history = model.fit(x_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QloNH4QqJFIp"
   },
   "source": [
    "## Accuracy of the testing dataset\n",
    "\n",
    "We use the ``evaluate`` function to return the loss value & metrics values for the model in test mode.\n",
    "\n",
    "The document of the ``evaluate`` function can be found in [here](https://keras.io/models/model/)\n",
    "\n",
    "我們使用 ``evaluate`` 函式來取得模型在 testing set 上的 accuracy。 \n",
    "\n",
    "``Evaluate`` 的文件可以在 [這裏](https://keras.io/models/model/) 找到."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19092,
     "status": "ok",
     "timestamp": 1584155565485,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "0I6kfFuVnKC9",
    "outputId": "f6109a7e-cd7d-4529-daa8-265a54b1a273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/sample - loss: 0.0972 - accuracy: 0.9778\n",
      "[0.09721309211519029, 0.9777778]\n",
      "Loss: 0.09721309211519029\n",
      "Accuracy: 0.9777777791023254\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test)\n",
    "print(result)\n",
    "print(f'Loss: {result[0]}')\n",
    "print(f'Accuracy: {result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZKsJkbpRnOo"
   },
   "source": [
    "## Draw the loss and accuracy when training the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1475,
     "status": "ok",
     "timestamp": 1584160706713,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "YhJgxULyR7Pt",
    "outputId": "a560bd31-2836-4d76-e55d-4c7f4950b171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f13e3d03e48>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.lineplot(x=np.linspace(1,501, num=500), y = history.history['accuracy'], label='Accuracy')\n",
    "sns.lineplot(x=np.linspace(1,501, num=500), y = history.history['loss'], label='Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 957,
     "status": "ok",
     "timestamp": 1584157415452,
     "user": {
      "displayName": "鍾毓驥",
      "photoUrl": "",
      "userId": "16037378104666941717"
     },
     "user_tz": -480
    },
    "id": "a7Ve9DSuq0dv",
    "outputId": "4ce6513b-87f0-4b71-ee3a-d0be9df1d3ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10694994 -0.55721505  0.70793846  1.50872803]\n",
      "[[-0.10694994 -0.55721505  0.70793846  1.50872803]]\n",
      "[[6.0429978e-05 2.9332722e-03 9.9700636e-01]]\n",
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0])\n",
    "print(x_test[0:1])\n",
    "y_pred = model.predict(x_test[0:1])\n",
    "print(y_pred)\n",
    "print(y_test[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNoywCMMM5juhkhdVMCCV3L",
   "collapsed_sections": [],
   "name": "DL.DNN_Iris.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
